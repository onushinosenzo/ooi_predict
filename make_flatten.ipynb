{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_soup(url):\n",
    "    req = requests.get(url)\n",
    "    \n",
    "    return BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_data(result_url):\n",
    "    soup = url_to_soup(result_url)\n",
    "    \n",
    "    going_ = soup.select(\"table.tb01\")[3].text.replace('\\n','　').split('　')[8]#予想レースの馬場状態\n",
    "    wether_ = soup.select(\"table.tb01\")[3].text.replace('\\n','　').split('　')[6]#予想レースの天候\n",
    "    len_ = int(soup.find(id=\"race-data01-a\").get_text().replace('\\n','').split('　')[3].replace(',','')[1:5])#予想レースの距離\n",
    "\n",
    "    win = int(re.sub('\\<.*?\\>','',str(soup.find_all('tr', class_='bg-1chaku')[0]).split('</td>')[2]).replace('\\n',''))\n",
    "    \n",
    "    return going_, wether_, len_, win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horse_page_link(uma_info_url):\n",
    "    soup = url_to_soup(uma_info_url)\n",
    "    link_lst = ['https://www.nankankeiba.com'+x.get('href') for x in soup.find_all('a', class_='tx-mid tx-low')]\n",
    "    \n",
    "    return link_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uma_info(url, going_, wether_, len_):\n",
    "    uma_df = pd.io.html.read_html(url)#馬のページから過去レースの表を取得\n",
    "    df = pd.DataFrame(uma_df[5])#表をdf形式にする\n",
    "    \n",
    "    feature = df.iloc[1:11,[1,4,5,8,9,10]]#表から欲しい特徴量の列だけ取得\n",
    "    feature = pd.concat([feature,feature[5].str.split('/', expand=True),feature[8].str.split('/', expand=True)], axis=1).drop([5,8],axis=1)#天候と馬場をバラしてdfに追加\n",
    "    feature.columns = range(0, len(feature.columns))#カラム名変えるために、カラムの番号をふる\n",
    "    feature.rename(columns={0:'place',1:'len',2:'time',3:'gap',4:'wether',5:'going',6:'rank',7:'cnt'},inplace=True)#カラム名変え\n",
    "    \n",
    "    \n",
    "    feature['place'].where((feature['place'] =='大井')|(feature['place']=='大井☆'), 0,inplace=True)#placeが大井と大井☆以外の要素を0にする\n",
    "    feature.loc[(feature['place']=='大井')|(feature['place']=='大井☆'), 'place'] = 1#placeが大井か大井☆の要素を1にする\n",
    "    \n",
    "    \n",
    "    feature['wether'].where(feature['wether'] == wether_, 0,inplace=True)#予想対象レースの天候と一致してなかったら0\n",
    "    feature.loc[feature['wether']==wether_, 'wether'] = 1#予想対象レースの天候と一致してたら1\n",
    "\n",
    "    \n",
    "    feature['going'].where(feature['going'] == going_, 0,inplace=True)#予想対象レースの馬場と一致してなかったら0\n",
    "    feature.loc[feature['going']==going_, 'going'] = 1#予想対象レースの馬場と一致してたら1\n",
    "    \n",
    "    #走行時間を秒に変換\n",
    "    try:\n",
    "        base_time = pd.to_datetime('00:00.0', errors='coerce', format='%M:%S.%f')\n",
    "        feature['time'] = pd.to_datetime(feature['time'], errors='coerce', format='%M:%S.%f') - base_time\n",
    "        feature['time'] = feature['time'].dt.total_seconds()\n",
    "    except ValueError:\n",
    "        base_time = pd.to_datetime('00.0', errors='coerce',format='%S.%f')\n",
    "        feature['time'] = pd.to_datetime(feature['time'], errors='coerce', format='%S.%f') - base_time\n",
    "        feature['time'] = feature['time'].dt.total_seconds()\n",
    "    \n",
    "    feature.loc[feature.gap.str.endswith(('除外','止','取消')),'gap'] = np.nan#レース中止の場合、gapの要素をNaNにする\n",
    "    feature.loc[feature.len.str.endswith('芝')] = np.nan#JRAのレースのデータをNaNにする\n",
    "    feature.fillna(feature.median(),inplace=True)#NaNに中央値を埋める\n",
    "    \n",
    "    \n",
    "    feature['len'] = abs(pd.Series(feature['len'],dtype=int) - len_)#予想対象レースの距離との差を絶対値にして返す\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_url(url):\n",
    "    soup = url_to_soup(url)\n",
    "    sp1 = soup.select('div em a')\n",
    "    sp2 = str(sp1).split(',')\n",
    "    sp3 = [i for i in sp2 if '大' in i]\n",
    "    \n",
    "    pr_url=[]\n",
    "    ends = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    race_info_list=[]\n",
    "    result_list=[]\n",
    "    \n",
    "    for i in range(len(sp3)):\n",
    "        p = sp3[i].split('.')\n",
    "        for x in range(len(ends)):\n",
    "            pr_url.append(p[0]+ends[x]+'.'+p[1])\n",
    "            \n",
    "    for i in pr_url:\n",
    "        race_info_list.append(i.split('\\n')[0].split('\"')[1].replace('program','race_info'))\n",
    "        result_list.append(i.split('\\n')[0].split('\"')[1].replace('program','result'))\n",
    "        \n",
    "    return race_info_list,result_list\n",
    "\n",
    "\n",
    "\n",
    "mother_url = ['https://www.nankankeiba.com/calendar/201204.do',\n",
    "'https://www.nankankeiba.com/calendar/201210.do',\n",
    "'https://www.nankankeiba.com/calendar/201304.do',\n",
    "'https://www.nankankeiba.com/calendar/201310.do',\n",
    "'https://www.nankankeiba.com/calendar/201404.do',\n",
    "'https://www.nankankeiba.com/calendar/201410.do',\n",
    "'https://www.nankankeiba.com/calendar/201504.do',\n",
    "'https://www.nankankeiba.com/calendar/201510.do',\n",
    "'https://www.nankankeiba.com/calendar/201604.do',\n",
    "'https://www.nankankeiba.com/calendar/201610.do',\n",
    "'https://www.nankankeiba.com/calendar/201704.do',\n",
    "'https://www.nankankeiba.com/calendar/201710.do',\n",
    "'https://www.nankankeiba.com/calendar/201804.do']\n",
    "\n",
    "race_info_lst=[]\n",
    "result_lst=[]\n",
    "for url in mother_url:\n",
    "    race_info_lst.append(pass_url(url)[0])\n",
    "    result_lst.append(pass_url(url)[1])\n",
    "\n",
    "new_race_info_lst = race_info_lst[0]\n",
    "new_result_lst = result_lst[0]\n",
    "for i in range(12):\n",
    "    new_race_info_lst = new_race_info_lst+race_info_lst[i]\n",
    "    new_result_lst = new_result_lst+result_lst[i]\n",
    "\n",
    "\n",
    "new_race_info_lst.remove('/race_info/2018012420170301.do')\n",
    "new_race_info_lst.remove('/race_info/2018012420170302.do')\n",
    "new_race_info_lst.remove('/race_info/2018012420170303.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170201.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170202.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170203.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170204.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170205.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170206.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170207.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170208.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170209.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170210.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170211.do')\n",
    "new_race_info_lst.remove('/race_info/2018012320170212.do')\n",
    "new_result_lst.remove('/result/2018012420170301.do')\n",
    "new_result_lst.remove('/result/2018012420170302.do')\n",
    "new_result_lst.remove('/result/2018012420170303.do')\n",
    "new_result_lst.remove('/result/2018012320170201.do')\n",
    "new_result_lst.remove('/result/2018012320170202.do')\n",
    "new_result_lst.remove('/result/2018012320170203.do')\n",
    "new_result_lst.remove('/result/2018012320170204.do')\n",
    "new_result_lst.remove('/result/2018012320170205.do')\n",
    "new_result_lst.remove('/result/2018012320170206.do')\n",
    "new_result_lst.remove('/result/2018012320170207.do')\n",
    "new_result_lst.remove('/result/2018012320170208.do')\n",
    "new_result_lst.remove('/result/2018012320170209.do')\n",
    "new_result_lst.remove('/result/2018012320170210.do')\n",
    "new_result_lst.remove('/result/2018012320170211.do')\n",
    "new_result_lst.remove('/result/2018012320170212.do')\n",
    "\n",
    "result_ = ['https://www.nankankeiba.com'+x for x in new_result_lst]\n",
    "race_info_ = ['https://www.nankankeiba.com'+x for x in new_race_info_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(result_, race_info_):\n",
    "    going_ = get_race_data(result_)[0]\n",
    "    wether_ = get_race_data(result_)[1]\n",
    "    len_ = get_race_data(result_)[2]\n",
    "    win = get_race_data(result_)[3]\n",
    "\n",
    "    link_lst = horse_page_link(race_info_)\n",
    "    \n",
    "    df_ = pd.DataFrame()\n",
    "    \n",
    "    #頭数足りない時用の0埋めデータフレーム作り\n",
    "    fill_z = np.zeros((10,8))\n",
    "    zero_ = pd.DataFrame(fill_z)\n",
    "    zero_.rename(columns={0:'place',1:'len',2:'time',3:'gap',4:'wether',5:'going',6:'rank',7:'cnt'},inplace=True)\n",
    "    #レース数足りない時用の0埋めデータフレーム作り\n",
    "    fill_z_ = np.zeros((1,8))\n",
    "    zero_row = pd.DataFrame(fill_z_)\n",
    "    zero_row.rename(columns={0:'place',1:'len',2:'time',3:'gap',4:'wether',5:'going',6:'rank',7:'cnt'},inplace=True)\n",
    "    \n",
    "    #df_に全特徴量をまとめる\n",
    "    for i in range(len(link_lst)):\n",
    "        if len(uma_info(link_lst[i], going_, wether_, len_).index) < 10:\n",
    "            df_ = df_.append(uma_info(link_lst[i], going_, wether_, len_))\n",
    "            for x in range(10 - len(uma_info(link_lst[i], going_, wether_, len_).index)):\n",
    "                df_ = df_.append(zero_row)\n",
    "        else:\n",
    "            df_ = df_.append(uma_info(link_lst[i], going_, wether_, len_))\n",
    "        \n",
    "    #16頭立てじゃないとき用の0埋め\n",
    "    for i in range(16-len(link_lst)):\n",
    "        df_ = df_.append(zero_)\n",
    "        \n",
    "    \n",
    "    #各インプット正規化\n",
    "    df_['len'] = df_['len']/df_['len'].max()\n",
    "    df_['time'] = df_['time']/df_['time'].max()\n",
    "    df_['gap'] = pd.Series(df_['gap'],dtype=float)/pd.Series(df_['gap'],dtype=float).max()\n",
    "    df_['rank'] = pd.Series(df_['rank'],dtype=float)/pd.Series(df_['rank'],dtype=float).max()\n",
    "    df_['cnt'] = pd.Series(df_['cnt'],dtype=float)/pd.Series(df_['cnt'],dtype=float).max()\n",
    "    \n",
    "    #df_をflattenデータにする\n",
    "    data_summary = df_.round(5).values.flatten()\n",
    "    \n",
    "    return data_summary ,win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_array = np.zeros((0,1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7869"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.66it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[1;34m(values, axis, skipna)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     27\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b187769d2892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace_info_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msum_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-121d16024538>\u001b[0m in \u001b[0;36msummary\u001b[1;34m(result_, race_info_)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gap'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cnt'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   9611\u001b[0m                                       skipna=skipna)\n\u001b[0;32m   9612\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[1;32m-> 9613\u001b[1;33m                             numeric_only=numeric_only)\n\u001b[0m\u001b[0;32m   9614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9615\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3219\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[0;32m   3220\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3221\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m         return delegate._reduce(op=op, name=name, axis=axis, skipna=skipna,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                     \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[1;34m(values, axis, skipna)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chainer\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     26\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     27\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "for i in range(len(result_)):\n",
    "\n",
    "\ta=summary(result_[i], race_info_[i])[0]\n",
    "\tsum_array = np.vstack((sum_array,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
